{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6b24292",
   "metadata": {},
   "source": [
    "## Patient data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249c44e9",
   "metadata": {},
   "source": [
    "### Machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "74f1283b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 1249 lines to ../data/Depmap_aligned.csv\n"
     ]
    }
   ],
   "source": [
    "input_file = \"D:/TCGA alighned/Celligner_aligned_data.csv\" #Big file, so read line by line\n",
    "#Download from https://figshare.com/articles/dataset/Celligner_data/11965269/4\n",
    "\n",
    "output_file = \"../data/Depmap_aligned.csv\" #Smaller file with only DepMap samples\n",
    "n = 0\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as infile, \\\n",
    "     open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    header = infile.readline()\n",
    "    outfile.write(header)\n",
    "    for line in infile:\n",
    "        if line.startswith(\"\\\"ACH-\"):\n",
    "            outfile.write(line)\n",
    "            n += 1\n",
    "print(f\"Extracted {n} lines to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6973b3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_exp = pd.read_csv(\"../data/Depmap_aligned.csv\",index_col=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f970c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = pd.read_csv(\"../cluster_hippo.csv\",index_col=0)\n",
    "clusterdic = {id: cluster.loc[id,\"Cluster\"] for id in cluster.index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4c2de553",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "df_exp_dep = df_exp[[d in clusterdic for d in df_exp.index]].dropna(axis=1,how=\"any\").copy()\n",
    "df_exp_dep = df_exp_dep.loc[:, df_exp_dep.std() != 0]\n",
    "normalized = StandardScaler().fit_transform(df_exp_dep)\n",
    "df_exp_dep = pd.DataFrame(normalized, index=df_exp_dep.index, columns=df_exp_dep.columns)\n",
    "\n",
    "X = df_exp_dep.values\n",
    "y = [clusterdic[d] for d in df_exp_dep.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761090b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed: 0,   Model: LogisticRegression0001\n",
      "Random Seed: 0,   Model: LogisticRegression001\n",
      "Random Seed: 0,   Model: LogisticRegression01\n",
      "Random Seed: 0,   Model: LogisticRegression1\n",
      "Random Seed: 0,   Model: RandomForest\n",
      "Random Seed: 0,   Model: XGBoost\n",
      "Random Seed: 1,   Model: LogisticRegression0001\n",
      "Random Seed: 1,   Model: LogisticRegression001\n",
      "Random Seed: 1,   Model: LogisticRegression01\n",
      "Random Seed: 1,   Model: LogisticRegression1\n",
      "Random Seed: 1,   Model: RandomForest\n",
      "Random Seed: 1,   Model: XGBoost\n",
      "Random Seed: 2,   Model: LogisticRegression0001\n",
      "Random Seed: 2,   Model: LogisticRegression001\n",
      "Random Seed: 2,   Model: LogisticRegression01\n",
      "Random Seed: 2,   Model: LogisticRegression1\n",
      "Random Seed: 2,   Model: RandomForest\n",
      "Random Seed: 2,   Model: XGBoost\n",
      "Random Seed: 3,   Model: LogisticRegression0001\n",
      "Random Seed: 3,   Model: LogisticRegression001\n",
      "Random Seed: 3,   Model: LogisticRegression01\n",
      "Random Seed: 3,   Model: LogisticRegression1\n",
      "Random Seed: 3,   Model: RandomForest\n",
      "Random Seed: 3,   Model: XGBoost\n",
      "Random Seed: 4,   Model: LogisticRegression0001\n",
      "Random Seed: 4,   Model: LogisticRegression001\n",
      "Random Seed: 4,   Model: LogisticRegression01\n",
      "Random Seed: 4,   Model: LogisticRegression1\n",
      "Random Seed: 4,   Model: RandomForest\n",
      "Random Seed: 4,   Model: XGBoost\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Fig. S8b, S8c\n",
    "#Cross Validation with multiple random seeds and baseline\n",
    "import pandas as pd\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, f1_score, balanced_accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "models = {\n",
    "    \"LogisticRegression0001\": LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000, C=0.001),\n",
    "    \"LogisticRegression001\": LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000, C=0.01),\n",
    "    \"LogisticRegression01\": LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000, C=0.1),\n",
    "    \"LogisticRegression1\": LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000, C=1),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "}\n",
    "results = []\n",
    "for seed in range(5):\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            for name, model in models.items():\n",
    "                print(f\"Random Seed: {seed},   Model: {name}\")\n",
    "                pipeline = Pipeline([('smote', SMOTE(random_state=seed)), ('model', model)])\n",
    "                y_proba = cross_val_predict(pipeline, X, y, cv=cv, method='predict_proba')\n",
    "                for threshold in [0.1,0.2,0.3,0.5]:\n",
    "                    y_pred = [4 if proba[4]>threshold else np.argmax(proba) for proba in y_proba]\n",
    "                    results.append({\n",
    "                    \"Method\": name,\n",
    "                    \"Seed\": seed,\n",
    "                    \"Threshold\": threshold,\n",
    "                    \"Accuracy\": accuracy_score(y, y_pred),\n",
    "                        \"Macro F1\": f1_score(y, y_pred, average='macro'),\n",
    "                        \"Weighted F1\": f1_score(y, y_pred, average='weighted'),\n",
    "                        \"Balanced Acc\": balanced_accuracy_score(y, y_pred)\n",
    "                    })\n",
    "\n",
    "# Baseline: Random\n",
    "for seed in range(5):\n",
    "    np.random.seed(seed)\n",
    "    y_unique = np.unique(y)\n",
    "    y_pred_random = np.random.choice(y_unique, size=len(y))\n",
    "    results.append({\n",
    "        \"Method\": \"Random Baseline\",\n",
    "        \"Seed\": seed,\n",
    "        'Threshold': 'N/A',\n",
    "        \"Accuracy\": accuracy_score(y, y_pred_random),\n",
    "        \"Macro F1\": f1_score(y, y_pred_random, average='macro'),\n",
    "        \"Weighted F1\": f1_score(y, y_pred_random, average='weighted'),\n",
    "        \"Balanced Acc\": balanced_accuracy_score(y, y_pred_random)\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results.to_csv('../result/ML_compare.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "71ed448b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.groupby(by=[\"Method\",\"Threshold\"]).mean().reset_index().sort_values('Macro F1',ascending=False)\n",
    "df_results.to_csv('../result/ML_compare.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9d23b34f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Weighted F1</th>\n",
       "      <th>Balanced Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.571362</td>\n",
       "      <td>0.592415</td>\n",
       "      <td>0.566457</td>\n",
       "      <td>0.626111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.582394</td>\n",
       "      <td>0.601905</td>\n",
       "      <td>0.578418</td>\n",
       "      <td>0.621193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.589671</td>\n",
       "      <td>0.607186</td>\n",
       "      <td>0.586145</td>\n",
       "      <td>0.618884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.588967</td>\n",
       "      <td>0.601492</td>\n",
       "      <td>0.585043</td>\n",
       "      <td>0.606628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.521831</td>\n",
       "      <td>0.546178</td>\n",
       "      <td>0.509946</td>\n",
       "      <td>0.599234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.552817</td>\n",
       "      <td>0.575497</td>\n",
       "      <td>0.547801</td>\n",
       "      <td>0.594593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression0001</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.540845</td>\n",
       "      <td>0.566094</td>\n",
       "      <td>0.539095</td>\n",
       "      <td>0.592780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression0001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.514319</td>\n",
       "      <td>0.540892</td>\n",
       "      <td>0.509028</td>\n",
       "      <td>0.589721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.549531</td>\n",
       "      <td>0.571206</td>\n",
       "      <td>0.549225</td>\n",
       "      <td>0.583322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.527700</td>\n",
       "      <td>0.553951</td>\n",
       "      <td>0.526919</td>\n",
       "      <td>0.582792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.552817</td>\n",
       "      <td>0.570863</td>\n",
       "      <td>0.548156</td>\n",
       "      <td>0.579536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression0001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.557746</td>\n",
       "      <td>0.574618</td>\n",
       "      <td>0.557004</td>\n",
       "      <td>0.577601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression001</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.538498</td>\n",
       "      <td>0.561604</td>\n",
       "      <td>0.538751</td>\n",
       "      <td>0.575870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression01</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.537559</td>\n",
       "      <td>0.558610</td>\n",
       "      <td>0.537087</td>\n",
       "      <td>0.575166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.523005</td>\n",
       "      <td>0.547194</td>\n",
       "      <td>0.523013</td>\n",
       "      <td>0.573622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.462207</td>\n",
       "      <td>0.480407</td>\n",
       "      <td>0.435349</td>\n",
       "      <td>0.572717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.542488</td>\n",
       "      <td>0.561239</td>\n",
       "      <td>0.541410</td>\n",
       "      <td>0.572297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.544366</td>\n",
       "      <td>0.564663</td>\n",
       "      <td>0.544399</td>\n",
       "      <td>0.571199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LogisticRegression01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.547887</td>\n",
       "      <td>0.563518</td>\n",
       "      <td>0.546142</td>\n",
       "      <td>0.569374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.550939</td>\n",
       "      <td>0.567034</td>\n",
       "      <td>0.550346</td>\n",
       "      <td>0.568030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LogisticRegression1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.538732</td>\n",
       "      <td>0.555789</td>\n",
       "      <td>0.538056</td>\n",
       "      <td>0.565074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LogisticRegression1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.543427</td>\n",
       "      <td>0.558274</td>\n",
       "      <td>0.541827</td>\n",
       "      <td>0.564458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogisticRegression1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.533099</td>\n",
       "      <td>0.552197</td>\n",
       "      <td>0.533255</td>\n",
       "      <td>0.564308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogisticRegression1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.525117</td>\n",
       "      <td>0.546764</td>\n",
       "      <td>0.526149</td>\n",
       "      <td>0.564103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Random Baseline</td>\n",
       "      <td>N/A</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.211033</td>\n",
       "      <td>0.205206</td>\n",
       "      <td>0.216417</td>\n",
       "      <td>0.211699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Method Threshold  Seed  Accuracy  Macro F1  Weighted F1  \\\n",
       "21                 XGBoost       0.1   2.0  0.571362  0.592415     0.566457   \n",
       "22                 XGBoost       0.2   2.0  0.582394  0.601905     0.578418   \n",
       "23                 XGBoost       0.3   2.0  0.589671  0.607186     0.586145   \n",
       "24                 XGBoost       0.5   2.0  0.588967  0.601492     0.585043   \n",
       "18            RandomForest       0.2   2.0  0.521831  0.546178     0.509946   \n",
       "19            RandomForest       0.3   2.0  0.552817  0.575497     0.547801   \n",
       "1   LogisticRegression0001       0.2   2.0  0.540845  0.566094     0.539095   \n",
       "0   LogisticRegression0001       0.1   2.0  0.514319  0.540892     0.509028   \n",
       "2   LogisticRegression0001       0.3   2.0  0.549531  0.571206     0.549225   \n",
       "4    LogisticRegression001       0.1   2.0  0.527700  0.553951     0.526919   \n",
       "20            RandomForest       0.5   2.0  0.552817  0.570863     0.548156   \n",
       "3   LogisticRegression0001       0.5   2.0  0.557746  0.574618     0.557004   \n",
       "5    LogisticRegression001       0.2   2.0  0.538498  0.561604     0.538751   \n",
       "9     LogisticRegression01       0.2   2.0  0.537559  0.558610     0.537087   \n",
       "8     LogisticRegression01       0.1   2.0  0.523005  0.547194     0.523013   \n",
       "17            RandomForest       0.1   2.0  0.462207  0.480407     0.435349   \n",
       "10    LogisticRegression01       0.3   2.0  0.542488  0.561239     0.541410   \n",
       "6    LogisticRegression001       0.3   2.0  0.544366  0.564663     0.544399   \n",
       "11    LogisticRegression01       0.5   2.0  0.547887  0.563518     0.546142   \n",
       "7    LogisticRegression001       0.5   2.0  0.550939  0.567034     0.550346   \n",
       "14     LogisticRegression1       0.3   2.0  0.538732  0.555789     0.538056   \n",
       "15     LogisticRegression1       0.5   2.0  0.543427  0.558274     0.541827   \n",
       "13     LogisticRegression1       0.2   2.0  0.533099  0.552197     0.533255   \n",
       "12     LogisticRegression1       0.1   2.0  0.525117  0.546764     0.526149   \n",
       "16         Random Baseline       N/A   2.0  0.211033  0.205206     0.216417   \n",
       "\n",
       "    Balanced Acc  \n",
       "21      0.626111  \n",
       "22      0.621193  \n",
       "23      0.618884  \n",
       "24      0.606628  \n",
       "18      0.599234  \n",
       "19      0.594593  \n",
       "1       0.592780  \n",
       "0       0.589721  \n",
       "2       0.583322  \n",
       "4       0.582792  \n",
       "20      0.579536  \n",
       "3       0.577601  \n",
       "5       0.575870  \n",
       "9       0.575166  \n",
       "8       0.573622  \n",
       "17      0.572717  \n",
       "10      0.572297  \n",
       "6       0.571199  \n",
       "11      0.569374  \n",
       "7       0.568030  \n",
       "14      0.565074  \n",
       "15      0.564458  \n",
       "13      0.564308  \n",
       "12      0.564103  \n",
       "16      0.211699  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.groupby(by=[\"Method\",\"Threshold\"]).mean().reset_index().sort_values('Balanced Acc',ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d69ff9a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Fig. S8d\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, f1_score, balanced_accuracy_score, confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('smote', SMOTE()), \n",
    "    ('logistic', LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000, C=0.001))\n",
    "])\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    y_proba = cross_val_predict(pipeline, X, y, cv=cv, method='predict_proba')\n",
    "y_pred = [4 if proba[4] > 0.2 else np.argmax(proba) for proba in y_proba]\n",
    "\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "macro_f1 = f1_score(y, y_pred, average='macro')\n",
    "weighted_f1 = f1_score(y, y_pred, average='weighted')\n",
    "balanced_acc = balanced_accuracy_score(y, y_pred)\n",
    "\n",
    "conf_matrix = confusion_matrix(y, y_pred, labels=[0, 1, 2, 3, 4])\n",
    "conf_matrix_normalized = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "df = pd.DataFrame(conf_matrix_normalized, columns=[f'Pred {i}' for i in range(5)], index=[f'True {i}' for i in range(5)])\n",
    "df.plot(kind='bar', stacked=True,  colormap=\"rainbow\",legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e74f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(pipeline, open(\"../model/logistic_regression_model.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1c1648ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ki949\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ki949\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained.\n"
     ]
    }
   ],
   "source": [
    "#ML for large TCGA data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def custom_predict(clf, X):\n",
    "    y_proba = clf.predict_proba(X)  # 予測確率を取得\n",
    "    y_pred = [4 if proba[4] > 0.2 else np.argmax(proba) for proba in y_proba]\n",
    "    return np.array(y_pred)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('smote', SMOTE()), \n",
    "    ('logistic', LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000, C=0.001))\n",
    "])\n",
    "pipeline.fit(X, y)\n",
    "print(\"Model trained.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cd334edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "135it [04:06,  1.82s/it]\n"
     ]
    }
   ],
   "source": [
    "# Predict on large TCGA data in chunks\n",
    "file_path = 'D:/TCGA alighned/Celligner_aligned_data.csv'\n",
    "#Download from https://figshare.com/articles/dataset/Celligner_data/11965269/4\n",
    "\n",
    "results = []\n",
    "relevant_cols = [d for d in df_exp_dep.columns]\n",
    "for chunk in tqdm(pd.read_csv(file_path, index_col=0, chunksize=100, iterator=True)):\n",
    "    if relevant_cols:\n",
    "        X_chunk = chunk[relevant_cols].values\n",
    "        y_pred = custom_predict(pipeline, X_chunk)\n",
    "        results.extend(zip(chunk.index, y_pred))\n",
    "\n",
    "results_df = pd.DataFrame(results, columns=['Index', 'Prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "df2fd570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TH27_1241_S01</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TARGET-40-0A4I65-01A-01R</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>THR24_1965_S01</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>THR24_2080_S01</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>THR20_0494_S01</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13480</th>\n",
       "      <td>ACH-000904</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13481</th>\n",
       "      <td>ACH-000110</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13482</th>\n",
       "      <td>ACH-000261</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13483</th>\n",
       "      <td>ACH-000031</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13484</th>\n",
       "      <td>ACH-000682</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13485 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Index  Prediction\n",
       "0                 TH27_1241_S01           2\n",
       "1      TARGET-40-0A4I65-01A-01R           4\n",
       "2                THR24_1965_S01           3\n",
       "3                THR24_2080_S01           4\n",
       "4                THR20_0494_S01           2\n",
       "...                         ...         ...\n",
       "13480                ACH-000904           2\n",
       "13481                ACH-000110           3\n",
       "13482                ACH-000261           4\n",
       "13483                ACH-000031           4\n",
       "13484                ACH-000682           3\n",
       "\n",
       "[13485 rows x 2 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1efcf2fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "y_pred = [4 if proba[4] > 0.2 else np.argmax(proba) for proba in y_proba]\n",
    "\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "macro_f1 = f1_score(y, y_pred, average='macro')\n",
    "weighted_f1 = f1_score(y, y_pred, average='weighted')\n",
    "balanced_acc = balanced_accuracy_score(y, y_pred)\n",
    "\n",
    "conf_matrix = confusion_matrix(y, y_pred, labels=[0, 1, 2, 3, 4])\n",
    "conf_matrix_normalized = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "df = pd.DataFrame(conf_matrix_normalized, columns=[f'Pred {i}' for i in range(5)], index=[f'True {i}' for i in range(5)])\n",
    "df.plot(kind='bar', stacked=True,  colormap=\"rainbow\",legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948d8559",
   "metadata": {},
   "source": [
    "### Kaplan Mier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eeb0b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pipeline = Pipeline([\n",
    "    ('smote', SMOTE()), \n",
    "    ('logistic', LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000, C=0.001))\n",
    "])\n",
    "\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "def custom_predict(clf, X):\n",
    "    y_proba = clf.predict_proba(X) \n",
    "    y_pred = [4 if proba[4]>0.3 else np.argmax(proba) for proba in y_proba]\n",
    "    return np.array(y_pred)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bca4b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "file_path = 'D:/TCGA alighned/Celligner_aligned_data.csv'\n",
    "#Download from https://figshare.com/articles/dataset/Celligner_data/11965269/4\n",
    "\n",
    "# 結果を保存するためのリスト\n",
    "results = []\n",
    "relevant_cols = [d[:-2] for d in df_merge2.columns]\n",
    "# 100列ずつデータを読み込んで処理\n",
    "for chunk in tqdm(pd.read_csv(file_path, index_col=0, chunksize=100, iterator=True)):\n",
    "    # 指定された列だけを抽出\n",
    "    #relevant_cols = [col for col in cols if col in chunk.columns]\n",
    "    \n",
    "    if relevant_cols:\n",
    "        X = chunk[relevant_cols].values\n",
    "        \n",
    "        # Clfを使って予測\n",
    "        y_pred = custom_predict(pipeline, X)\n",
    "        \n",
    "        # Indexと予測結果を保存\n",
    "        results.extend(zip(chunk.index, y_pred))\n",
    "\n",
    "# 結果をデータフレームとして保存\n",
    "results_df = pd.DataFrame(results, columns=['Index', 'Prediction'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
